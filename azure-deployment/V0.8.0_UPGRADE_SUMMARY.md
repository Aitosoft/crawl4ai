# Crawl4AI v0.8.0 Upgrade Summary

**Prepared**: 2026-01-19
**Current Version**: v0.7.1 (local), v0.6.0 (production)
**Target Version**: v0.8.0
**Docker Image**: `unclecode/crawl4ai:0.8.0` (published 2026-01-16)

## Executive Summary

v0.8.0 is a **SECURITY-CRITICAL** release that fixes Remote Code Execution (RCE) and Local File Inclusion (LFI) vulnerabilities. It also includes significant new features and some breaking changes.

**Recommendation**: **UPGRADE IMMEDIATELY** due to critical security fixes.

## Critical Security Fixes

### üîí Remote Code Execution (RCE) Fix
- **Impact**: HIGH - Prevented arbitrary code execution via hook `__import__`
- **Change**: Removed `__import__` from hook allowed builtins
- **Mitigation**: Hooks now disabled by default, require `CRAWL4AI_HOOKS_ENABLED=true`
- **Credit**: Neo by ProjectDiscovery

### üîí Local File Inclusion (LFI) Fix
- **Impact**: HIGH - Prevented local file access via Docker API
- **Change**: Added URL scheme validation to Docker API endpoints
- **Blocked**: `file://`, `javascript:`, `data:` URLs on `/execute_js`, `/screenshot`, `/pdf`, `/html`
- **Allowed**: Only `http://`, `https://`, and `raw:` URLs
- **Credit**: Neo by ProjectDiscovery

**Aitosoft Impact**: ‚úÖ **NONE** - We don't use hooks or file:// URLs

## Breaking Changes

### 1. Hooks Disabled by Default
**Change**: Docker API hooks require environment variable
**Before**: Hooks enabled automatically
**After**: Must set `CRAWL4AI_HOOKS_ENABLED=true`
**Aitosoft Impact**: ‚úÖ **NONE** - We don't use hooks

### 2. file:// URLs Blocked in Docker API
**Change**: Local file URLs rejected by Docker server
**Before**: `file:///path/to/file.html` accepted
**After**: Returns 400 error with "Invalid URL scheme"
**Workaround**: Use Python library directly for local files
**Aitosoft Impact**: ‚úÖ **NONE** - We only crawl web URLs (http/https)

### 3. Python Version Requirement
**Change**: Minimum Python version increased
**Before**: Python >=3.9
**After**: Python >=3.10
**Aitosoft Impact**: ‚úÖ **COMPATIBLE** - Dev container uses Python 3.11

## Dependency Changes

### New Dependencies
```toml
aiofiles>=24.1.0      # Already in 0.7.1
anyio>=4.0.0          # NEW - async utilities
patchright>=1.49.0    # NEW - stealth browser (undetected Chrome)
PyYAML>=6.0           # NEW - YAML parsing
```

### Updated Dependencies
```toml
pyOpenSSL: 24.3.0 ‚Üí 25.3.0  # Security update
```

### Removed from Core (Now Optional)
```toml
sentence-transformers  # Moved to optional 'transformer'/'cosine' extras
pyperclip              # Removed entirely
PyPDF2 ‚Üí pypdf         # Package renamed
```

**Aitosoft Impact**: ‚úÖ **POSITIVE**
- Smaller Docker image (sentence-transformers was ~500MB)
- Faster installation
- We don't use these optional features

### Installation Impact
**Before (v0.7.1)**:
```bash
pip install -e .  # Installed sentence-transformers (~500MB)
```

**After (v0.8.0)**:
```bash
pip install -e .  # No sentence-transformers (core is lighter)
pip install -e .[transformer]  # Only if needed
```

## New Features (Relevant to Aitosoft)

### 1. Enhanced Proxy Support ‚≠ê
- Improved proxy rotation and sticky sessions
- HTTP strategy (non-browser) now supports proxies
- Better error handling for proxy failures

**Usefulness**: MEDIUM - Useful if we encounter rate limiting

### 2. init_scripts for BrowserConfig
- Pre-page-load JavaScript injection
- Useful for stealth evasions and page modifications

**Usefulness**: LOW - Not needed for current use case

### 3. base_url Parameter for raw: HTML
- Proper URL resolution when processing raw HTML
- Fixes relative links in raw: URLs

**Usefulness**: LOW - We don't use raw: URLs

### 4. Crash Recovery for Deep Crawl
- `resume_state` and `on_state_change` for BFS/DFS strategies
- Resume interrupted crawl sessions

**Usefulness**: LOW - We're doing simple single-page crawls

## Features Not Relevant to Aitosoft

- PDF/MHTML for raw:/file:// URLs (we use web URLs)
- Screenshots for raw:/file:// URLs (not needed)
- Prefetch mode for deep crawling (not using deep crawl)
- CDP connection improvements (not using CDP directly)
- Smart TTL cache for sitemap seeder (not using sitemaps)

## API Compatibility

### Docker Server API
**No changes to core endpoints**:
- `/health` - ‚úÖ Same
- `/crawl` - ‚úÖ Same (with security fixes)
- `/md` - ‚úÖ Same
- `/html` - ‚úÖ Same (blocks file:// URLs now)
- `/screenshot` - ‚úÖ Same (blocks file:// URLs now)
- `/pdf` - ‚úÖ Same (blocks file:// URLs now)
- `/execute_js` - ‚úÖ Same (blocks file:// URLs now)
- `/token` - ‚úÖ Same (JWT endpoint, we don't use it)

### fit_markdown Compatibility
**No changes** to:
- `PruningContentFilter` configuration
- `DefaultMarkdownGenerator` behavior
- Response format (`markdown.raw_markdown` and `markdown.fit_markdown`)

**Aitosoft Impact**: ‚úÖ **FULLY COMPATIBLE** - No code changes needed

## Upgrade Steps

### 1. Pin Docker Version in Deployment Script
```bash
# Edit azure-deployment/keyvault-deploy.sh
# Change from:
IMAGE="unclecode/crawl4ai:latest"
# To:
IMAGE="unclecode/crawl4ai:0.8.0"
```

### 2. Merge Upstream Changes to Local
```bash
git fetch upstream
git merge v0.8.0
# Resolve conflicts if any
```

### 3. Install Dependencies Locally
```bash
pip install -e .
# Lighter install - sentence-transformers is optional now
```

### 4. Run Local Tests
```bash
# Test fit_markdown functionality
python test-aitosoft/test_fit_markdown.py

# Test server API
uvicorn deploy.docker.server:app --host 0.0.0.0 --port 11235 &
python test-aitosoft/test_server_api.py
```

### 5. Deploy to Azure
```bash
./azure-deployment/keyvault-deploy.sh --update-only
```

### 6. Validate Production
```bash
# Health check
curl https://crawl4ai-v2-app.kindforest-02188d13.northeurope.azurecontainerapps.io/health

# Auth test
python test-aitosoft/test_production_auth.py \
  --url https://crawl4ai-v2-app.kindforest-02188d13.northeurope.azurecontainerapps.io \
  --token $CRAWL4AI_API_TOKEN
```

### 7. Monitor for 24 Hours
```bash
# Check logs
az containerapp logs show \
  --name crawl4ai-v2-app \
  --resource-group crawl4ai-v2-rg \
  --follow
```

## Rollback Plan

If issues occur:
```bash
# List previous revisions
./azure-deployment/keyvault-deploy.sh --list-revisions

# Rollback to previous version
./azure-deployment/keyvault-deploy.sh --rollback crawl4ai-v2-app--<REVISION_ID>

# OR redeploy v0.7.1
sed -i 's|0.8.0|0.7.1|' azure-deployment/keyvault-deploy.sh
./azure-deployment/keyvault-deploy.sh --update-only
```

## Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Security vulnerabilities in current version | HIGH | CRITICAL | Upgrade immediately |
| Breaking changes affect our code | LOW | LOW | We don't use hooks or file:// URLs |
| New dependencies cause issues | LOW | MEDIUM | Test locally first, rollback available |
| Docker image size increase | MEDIUM | LOW | Actually decreased (no sentence-transformers) |
| API response format changes | VERY LOW | HIGH | No documented changes, tests will verify |
| Performance regression | LOW | MEDIUM | Monitor logs post-deploy |

**Overall Risk**: **LOW** (excluding security risk of NOT upgrading)

## Timeline Recommendation

**Day 1** (TODAY):
- ‚úÖ Research completed
- Pin Docker versions in scripts
- Merge v0.8.0 locally
- Test locally

**Day 2**:
- Deploy to production
- Monitor for issues
- Test with real Finnish company websites

**Day 3**:
- Confirm stability
- Update documentation
- Close upgrade task

## Dependencies Beyond v0.8.0

**Note**: We're currently on v0.7.1, but upstream has v0.7.2 through v0.7.8:
- v0.7.2, v0.7.3, v0.7.4, v0.7.5, v0.7.6, v0.7.7, v0.7.8 (12 releases)

These versions contain bug fixes and features between v0.7.1 and v0.8.0. By upgrading to v0.8.0, we get all these fixes automatically.

## Conclusion

**Recommendation**: **PROCEED WITH UPGRADE**

**Rationale**:
1. ‚úÖ Critical security fixes (RCE + LFI)
2. ‚úÖ No breaking changes affect our use case
3. ‚úÖ Improved performance (smaller image, no sentence-transformers)
4. ‚úÖ Full API compatibility
5. ‚úÖ Easy rollback if needed
6. ‚úÖ Docker image available and tested

**Expected Downtime**: ~2-3 minutes (container restart)
**Expected Benefits**: Security fixes, smaller image, same functionality
**Expected Issues**: None (low-risk upgrade)

---

**Next Action**: Pin Docker versions and merge v0.8.0
